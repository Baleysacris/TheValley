# Clase 1 - Modelos de árboles avanzados 
Profundizamos en modelos de árboles avanzados e introducimos el concepto (en realidad ya conocido) de model ensambles:
- Último repaso a modelos de árboles de decisión
- Model Ensembles: ¿suma de modelos débiles = modelo fuerte?
  - Bagging: Random Forests
  - Boosting: Gradient Boosting, Stochastic Gradient Boosting, AdaBoost, XGBoost
  - Stacking

Los materiales que utilizaremos son:
- [Presentación](https://docs.google.com/presentation/d/1OpMCZdoi_caj86x-_HqZVaCMWASUDKSis-sMKsKI1eM/edit?usp=sharing) | [Presentación formato claro](https://docs.google.com/presentation/d/1F68d62Vskya9lSi8nwJfQxRqMqdVk3_I0c61jgtSWWg/edit?usp=sharing)
- Cuestionarios de [Kahoot](https://kahoot.it/):
  - [Cuestionario 1](https://create.kahoot.it/details/66d8870b-abba-4254-8175-4f1e721102b6)
  - [Cuestionario 2](https://create.kahoot.it/details/32e2b50b-0a42-4937-b45d-9518e4977127)  
- 1A - Notebook Práctica Ejercicios: Original | Resuelto


# Clase 2 - Optimizando modelos: selección de hiperparámetros
Cómo buscar y seleccionar el mejor set de hiperparámetros posible a la hora de entrenar un modelo:
- Creación de pipelines para crear modelos ensamblados
- Principios de búsqueda de hiperparámetros
- Búsqueda de parámetros y selección de features
- Grid search, random search o basados en otras técnicas

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook ...: Original | Resuelto
- 2B - Notebook ...: Original | Resuelto 

# Clase 3 - Introducción a las redes neuronales
Introducción a modelos de redes neuronales:
- Qué es una red neuronal?
- Tipología: Neuronas, Capas, Etc.
Función de activación: sigmoide/relu
- Gradiente Descento y proceso de aprendizaje (backpropagation)
- Función de pérdida
- Sotochastic Gradient Descent
- ver mail con link

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook ...: Original | Resuelto
- 2B - Notebook ...: Original | Resuelto 
