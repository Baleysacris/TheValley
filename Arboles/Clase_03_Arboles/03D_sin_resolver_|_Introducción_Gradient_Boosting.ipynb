{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03D | Introducción Gradient Boosting.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNSJ09xwjb+hZEattwXaBRB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03D_sin_resolver_%7C_Introducci%C3%B3n_Gradient_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R53FGLN8jo1L"
      },
      "source": [
        "# 01 INTRODUCCIÓN: Gradient Boosting\n",
        "Introducción a modelos de agregación de árboles de decisión con Gradient Boosting.\n",
        "\n",
        "Notebook por [Javier Blanco Cordero](https://www.linkedin.com/in/javier-blanco-cordero-71373656/).\n",
        "\n",
        "### Enlaces de interés\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/1jRg7Dk2y_2_fxnC_Jpj5aWcqgW9t1KAd7izdmWzv9Sk/edit?usp=sharing)\n",
        "*   [Enlace a este notebook](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03A_%7C_Repaso_I_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSuEDXhPLi8u"
      },
      "source": [
        "## 0101 Qué es un Gradient Boosting?\n",
        "Un tipo de algoritmo de aprendizaje supervisado que se basa la agregación en serie de árboles de decisión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHRaho3rsXS"
      },
      "source": [
        "## 0102 Import\n",
        "Importamos todas las librerías necesarias para este análisis ([¿No sabes lo que es una librería de Python?](https://www.quora.com/What-is-a-Python-library-and-what-can-I-use-it-for)): pandas, numpy, seaborn, matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be6xiUqjPHI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV7JfD4SgZOm"
      },
      "source": [
        "## 0103 Carga el dataset del Titanic\n",
        "Volvamos con el Dataset del Titanic\n",
        "\n",
        "Vamos a comparar el rendimiento de un Random Forest con los modelos de árboles de decisión que creamos en el [notebook 3B](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03B_%7C_Repaso_II_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb).\n",
        "\n",
        "Este es el link al archivo raw: https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv.\n",
        "\n",
        "Importa los datos en un dataframe llamado **dataframe df_titanic**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyreCClfgW64"
      },
      "source": [
        "# Url archivo raw\n",
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv'\n",
        "\n",
        "# Importa csv\n",
        "df_titanic = pd.read_csv(url)\n",
        "\n",
        "# Visualización primeras filas\n",
        "df_titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K99LUAvEgkaO"
      },
      "source": [
        "## 0104 Limpieza del Dataset\n",
        "Limpiamos los nulos y creamos la variable Title como en el [Notebook 3B](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03B_%7C_Repaso_II_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb) y en el [Notebook 3C](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03C_%7C_Introducci%C3%B3n_Random_Forests.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYL8wXNUgW-F"
      },
      "source": [
        "# Creamos una nueva variable Título (es opcional, pero podría ayudar al modelo)\n",
        "df_titanic['Title'] = [name.split(\",\")[1].split(\".\")[0][1:] for name in df_titanic['Name']]\n",
        "df_titanic.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMVCMVy4gXBU"
      },
      "source": [
        "# Columnas con las que nos quedamos\n",
        "cols = ['Survived', \n",
        "        'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title']\n",
        "\n",
        "# De ellas, cuáles son categóricas\n",
        "cat_cols = ['Sex', 'Embarked', 'Title']\n",
        "\n",
        "# Visualizamos las columnas con las que nos hemos quedado\n",
        "df_titanic[cols].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2-c2GzigXEd"
      },
      "source": [
        "# Rellenamos los nulos de las variables numéricas (edad)\n",
        "df_titanic[cols].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLfHmw1YgXHj"
      },
      "source": [
        "# Rellenamos los nulos de la variable edad de una forma avanzada:\n",
        "# calculando la media para cada título\n",
        "\n",
        "filtro_edad_nula = df_titanic['Age'].isna()\n",
        "filtro_edad_no_nula = df_titanic['Age'].notnull()\n",
        "\n",
        "# Rellenamos los nulos en función del título \n",
        "for titulo in df_titanic['Title'].unique():\n",
        "  filtro_titulo = df_titanic['Title'] == titulo\n",
        "\n",
        "  if len(df_titanic[((filtro_titulo) & (filtro_edad_no_nula))]) > 2:\n",
        "    print(titulo)\n",
        "    df_titanic.loc[((filtro_titulo)&(filtro_edad_nula)), 'Age'] = df_titanic.loc[((filtro_titulo)&(filtro_edad_no_nula)), 'Age'].median()\n",
        "  \n",
        "# Rellenamos los que sigan siendo nulos (títulos solo presentes entre gente sin la edad informada)\n",
        "df_titanic['Age'] = df_titanic['Age'].fillna(df_titanic['Age'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygVbZJmZgXKs"
      },
      "source": [
        "# Eliminamos los nulos de la variable Embarked\n",
        "print(len(df_titanic))\n",
        "df_titanic = df_titanic.dropna(subset=['Embarked'])\n",
        "print(len(df_titanic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1bAPTWdgXN_"
      },
      "source": [
        "# Dumificamos variables categóricas\n",
        "df_titanic_i = pd.get_dummies(df_titanic[cols], \n",
        "                              prefix_sep='_',\n",
        "                              drop_first=True, \n",
        "                              columns=cat_cols)\n",
        "df_titanic_i.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpxU9iNuhekT"
      },
      "source": [
        "## 0105 Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTXiGh9ygXQ-"
      },
      "source": [
        "# Generamos las matrices X e y\n",
        "X_titanic = df_titanic_i.drop('Survived',axis=1)\n",
        "y_titanic = df_titanic_i['Survived']\n",
        "\n",
        "X_titanic.shape, y_titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBvVZ0TLgXUt"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic, \n",
        "                                                    y_titanic, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZI6Z8LFWhqqV"
      },
      "source": [
        "# 02 Entrenamiento árbol de decisión\n",
        "Entrenamos un árbol de decisión tomando medidas para evitar el overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDu7pq5FgXXH"
      },
      "source": [
        "def entrenar_modelo_y_predecir_classificacion(modelo):\n",
        "  # Entreno el árbol con el set de entrenamiento\n",
        "  modelo = modelo.fit(X=X_train, y=y_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de entrenamiento\n",
        "  y_pred_train = modelo.predict(X_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de test\n",
        "  y_pred_test = modelo.predict(X_test)\n",
        "  # Cómo de buena es la predicción?\n",
        "  ac_train = round(accuracy_score(y_train, y_pred_train), 4)\n",
        "  print('Precisión en set de entrenamiento :', ac_train)\n",
        "  ac_test = round(accuracy_score(y_test, y_pred_test), 4)\n",
        "  print('Precisión en set de test :', ac_test)\n",
        "  print('Degradación: ', round((ac_train-ac_test)/ac_train*100,2), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnVBHCKwh1Y0"
      },
      "source": [
        "arbol_decision = tree.DecisionTreeClassifier(max_depth=20, \n",
        "                                             min_samples_split = 20,\n",
        "                                             min_samples_leaf = 5, \n",
        "                                             min_impurity_decrease = 0.003)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(arbol_decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pPvxoQtiJCd"
      },
      "source": [
        "# 03 Entrenamiento Random Forest\n",
        "Ahora comparamos el rendimiento del árbol de decisión con un Random Forest.\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxCr7cdOh1gf"
      },
      "source": [
        "random_forest = ensemble.RandomForestClassifier(n_estimators = 200,\n",
        "                                                max_depth = 3, \n",
        "                                                min_samples_split = 10,\n",
        "                                                min_samples_leaf = 5)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(random_forest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TOhhEWdidon"
      },
      "source": [
        "# 04 Gradient Boosting\n",
        "Utilizaremos de nuevo la implementación de sklearn, que podéis ver aquí: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5_QrOvp9iwH"
      },
      "source": [
        "grad_boost = ensemble.GradientBoostingClassifier()\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(grad_boost)\n",
        "\n",
        "print()\n",
        "grad_boost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZgeg3Ah1mn"
      },
      "source": [
        "grad_boost = ensemble.GradientBoostingClassifier(n_estimators = 100, \n",
        "                                                 learning_rate = 0.1,\n",
        "                                                 max_depth = 5, \n",
        "                                                 min_samples_split = 20,\n",
        "                                                 min_samples_leaf = 5,\n",
        "                                                 min_impurity_decrease = 0.01,\n",
        "                                                 random_state = 0)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(grad_boost)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6A5aXDG1L9L"
      },
      "source": [
        "# 05 EJERCICIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbWF2wrO1OmL"
      },
      "source": [
        "## 0501 Importa Dataset Diabetes\n",
        "Vamos a utilizar el dataset del notebook 3A (Diabetes).\n",
        "\n",
        "Impórtalo utilizando el archivo raw: 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/diabetesIndia.csv'.\n",
        "\n",
        "Guárdalo en el **dataframe df**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLy2rRJ8h1p2"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/diabetesIndia.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKB-L2nG1Vc2"
      },
      "source": [
        "## 0502 Limpia el dataset\n",
        "Comprueba el dataset (hay nulos) y prepáralo si es necesario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vfw7aElxK26"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmeHRt9w1cEC"
      },
      "source": [
        "## 0503 Train-Test split\n",
        "Genera el set de pruebas (test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEYTaJU9xK6c"
      },
      "source": [
        "# Generamos las matrices X e y\n",
        "X = ...\n",
        "y = ...\n",
        "\n",
        "# Comprueba sus tamaños\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMAvxqaW1fnn"
      },
      "source": [
        "# Genera X_train, X_test, y_train, y_test\n",
        "...\n",
        "\n",
        "# Comprueba sus tamaños\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjsiS_QE1jLW"
      },
      "source": [
        "## 0504 Árbol de Decisión\n",
        "Encuentra el mejor árbol de decisión posible (ya lo hiciste en el [Notebook 3C](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03C_%7C_Introducci%C3%B3n_Random_Forests.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3iOWj8l1hE6"
      },
      "source": [
        "# Como has hecho en el Notebook 3B y 3C\n",
        "modelo = ...\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvRI3mhh12wb"
      },
      "source": [
        "## 0505 Random Forest\n",
        "Encuentra el mejor modelo de rándom forest posible (ya lo hiciste en el [Notebook 3C](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03C_%7C_Introducci%C3%B3n_Random_Forests.ipynb))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvE04aND10m-"
      },
      "source": [
        "# Como has hecho en el Notebook 3C\n",
        "modelo = ...\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NypBcBCL2FWk"
      },
      "source": [
        "## 0506 Gradient Boosting\n",
        "Encuentra el mejor modelo de gradient boosting posible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57WT5p7A2AV9"
      },
      "source": [
        "modelo = ...\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}