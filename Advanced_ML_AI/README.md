# Clase 1 - Modelos de árboles avanzados 
Profundizamos en modelos de árboles avanzados e introducimos el concepto (en realidad ya conocido) de model ensambles:
- Último repaso a modelos de árboles de decisión
- Model Ensembles: ¿suma de modelos débiles = modelo fuerte?
  - Bagging: Random Forests
  - Boosting: Gradient Boosting, Stochastic Gradient Boosting, AdaBoost, XGBoost
  - Stacking

Los materiales que utilizaremos son:
- [Presentación](https://docs.google.com/presentation/d/1OpMCZdoi_caj86x-_HqZVaCMWASUDKSis-sMKsKI1eM/edit?usp=sharing) | [Presentación formato claro](https://docs.google.com/presentation/d/1F68d62Vskya9lSi8nwJfQxRqMqdVk3_I0c61jgtSWWg/edit?usp=sharing)
- Cuestionarios de [Kahoot](https://kahoot.it/):
  - [Cuestionario 1](https://create.kahoot.it/details/66d8870b-abba-4254-8175-4f1e721102b6)
  - [Cuestionario 2](https://create.kahoot.it/details/32e2b50b-0a42-4937-b45d-9518e4977127)  
- 1A - Notebook Práctica Ejercicios: [Original](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Advanced_ML_AI/Clase_01_Modelos_Avanzados_%C3%81rboles/01A_%7C_Ejercicio_Coches_y_Casas_sin_resolver.ipynb) | [Resuelto](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Advanced_ML_AI/Clase_01_Modelos_Avanzados_%C3%81rboles/01A_%7C_Ejercicio_Coches_y_Casas.ipynb)


# Clase 2 - Optimizando modelos: selección de hiperparámetros
Primero, veremos el método de ensamblaje de modelos que no nos dio tiempo a tratar en la clase anterior:
- Repaso de métodos de ensamblaje de modelos y algoritmos específicos que se basan en ellos: Random Forest, Gradient Boosting, AdaBoost, XGBoost
- Énfasis en el método de ensamblaje de modelo que nos quedaba por ver: Stacking

Luego, veremos cómo buscar y seleccionar el mejor set de hiperparámetros posible a la hora de entrenar un modelo:
- Principios de búsqueda de hiperparámetros
- Grid search, random search o basados en otras técnicas

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook Practica Ensamblaje de Modelos: [Original](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Advanced_ML_AI/Clase_02_Optimizacion_Modelos/02A_%7C_Notebook_Pr%C3%A1ctica_Ensamblaje_e_Hiperpar%C3%A1metros_sin_resolver.ipynb) | [Resuelto](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Advanced_ML_AI/Clase_02_Optimizacion_Modelos/02A_%7C_Notebook_Pr%C3%A1ctica_Ensamblaje_e_Hiperpar%C3%A1metros.ipynb)
- 2B - Ejercicio Challenge: [Notebook](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Advanced_ML_AI/Clase_02_Optimizacion_Modelos/02B_%7C_Ejercicio_CHALLENGE.ipynb) 

# Clase 3 - Introducción a las redes neuronales
Introducción a modelos de redes neuronales:
- Qué es una red neuronal?
- Tipología: Neuronas, Capas, Etc.
Función de activación: sigmoide/relu
- Gradiente Descento y proceso de aprendizaje (backpropagation)
- Función de pérdida
- Sotochastic Gradient Descent
- ver mail con link

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook ...: Original | Resuelto
- 2B - Notebook ...: Original | Resuelto 
