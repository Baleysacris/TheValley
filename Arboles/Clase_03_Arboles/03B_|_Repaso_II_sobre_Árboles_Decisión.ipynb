{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03B | Repaso II sobre Árboles Decisión.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPUyuo5YMd5gQQoIb99VjqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03B_%7C_Repaso_II_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R53FGLN8jo1L"
      },
      "source": [
        "# 01 REPASO II: Árboles de Decisión\n",
        "Repaso sobre cómo utilizar árboles de decisión y cómo realizar la preparación previa de los datos.\n",
        "\n",
        "Notebook por [Javier Blanco Cordero](https://www.linkedin.com/in/javier-blanco-cordero-71373656/).\n",
        "\n",
        "### Enlaces de interés\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/1jRg7Dk2y_2_fxnC_Jpj5aWcqgW9t1KAd7izdmWzv9Sk/edit?usp=sharing)\n",
        "*   [Enlace a este notebook](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03A_%7C_Repaso_I_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSuEDXhPLi8u"
      },
      "source": [
        "## 0101 Qué es un árbol de decisión?\n",
        "Un tipo de algoritmo de aprendizaje supervisado que se basa en realizar particiones recursivas a partir de distintos niveles de las variables disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHRaho3rsXS"
      },
      "source": [
        "## 0102 Import\n",
        "Importamos todas las librerías necesarias para este análisis ([¿No sabes lo que es una librería de Python?](https://www.quora.com/What-is-a-Python-library-and-what-can-I-use-it-for)): pandas, numpy, seaborn, matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be6xiUqjPHI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AblkT14d4Gvt"
      },
      "source": [
        "## 0103 Carga el dataset del Titanic\n",
        "Recordais el dataset del Titanic?\n",
        "\n",
        "Vamos a hacer un árbol de decisión que prediga si alguien fallece o no, pero esta vez el dataset no está ya limpio y preparado. Este mismo ejemplo lo resolvisteis en el [notebook 2C](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_02_Arboles/02_C_%C3%81rboles_Decisi%C3%B3n_sin_Overfitting_Resuelto.ipynb#scrollTo=EDiMGl7xOm6o).\n",
        "\n",
        "Para ello utilizaremos el dataset original. Este es el link al archivo raw: https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv.\n",
        "\n",
        "Importa los datos en un dataframe llamado **dataframe df_titanic**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZACcIXOclu"
      },
      "source": [
        "# Url archivo raw\n",
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv'\n",
        "\n",
        "# Importa csv\n",
        "df_titanic = pd.read_csv(url)\n",
        "\n",
        "# Visualización primeras filas\n",
        "df_titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOQJ0AjdYrM"
      },
      "source": [
        "# 02 EDA\n",
        "Realizaremos un pequeño análisis exploratorio visual para familiarizarnos con el dataset. \n",
        "\n",
        "Recuerda que puedes encontrar mis clases sobre análisis exploratorio [aquí](https://github.com/JotaBlanco/TheValley/tree/main/EDA/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGrwhGyaj0-a"
      },
      "source": [
        "df_titanic.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LoZpl8rjWEX"
      },
      "source": [
        "df_titanic.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUz-qSwBjaEW"
      },
      "source": [
        "# Visualización coeficientes Pearson\n",
        "plt.figure(figsize=(8,7))\n",
        "sns.heatmap(np.round(df_titanic.corr(),2), \n",
        "            vmin=-1, vmax=1, \n",
        "            annot=True, cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OJS0b4R5ZNh"
      },
      "source": [
        "# 03 Preparación de los datos\n",
        "Primero prepararemos el dataset para que admita un entrenamiento de un árbol de decisión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wguISKl5q_h"
      },
      "source": [
        "## 0301 Creación de variables\n",
        "Primero, vamos a crear una variable nueva:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqcX-sFQ5krb"
      },
      "source": [
        "# Creamos una nueva variable Título (es opcional, pero podría ayudar al modelo)\n",
        "df_titanic['Title'] = [name.split(\",\")[1].split(\".\")[0][1:] for name in df_titanic['Name']]\n",
        "df_titanic.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOdoBzd46La9"
      },
      "source": [
        "## 0302 Seleccionamos variables\n",
        "Nos quedamos con las variables que utilizaremos. \n",
        "\n",
        "Descartamos ciertas columnas como el nombre, o la cabina: tienen muchas posibles categorías, y no deberían ser buenas para predecir el target sobre datos aún no vistos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThnP11iE5kvJ"
      },
      "source": [
        "df_titanic.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WOnu2t85k2I"
      },
      "source": [
        "# Columnas con las que nos quedamos\n",
        "cols = ['Survived', \n",
        "        'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title']\n",
        "\n",
        "# De ellas, cuáles son categóricas\n",
        "cat_cols = ['Sex', 'Embarked', 'Title']\n",
        "\n",
        "# Visualizamos las columnas con las que nos hemos quedado\n",
        "df_titanic[cols].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBvgESsE7GUy"
      },
      "source": [
        "## 0303 Limpieza de nulos\n",
        "Los árboles de decisión no admiten nulos, por lo que tenemos que hacer algo con ellos (eliminarlos o rellenarlos con ciertos valores)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1pmWM-S5k6Z"
      },
      "source": [
        "# Rellenamos los nulos de las variables numéricas (edad)\n",
        "df_titanic[cols].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_OV2MiE69iZ"
      },
      "source": [
        "# Rellenamos los nulos de la variable edad de una forma avanzada:\n",
        "# calculando la media para cada título\n",
        "\n",
        "filtro_edad_nula = df_titanic['Age'].isna()\n",
        "filtro_edad_no_nula = df_titanic['Age'].notnull()\n",
        "\n",
        "# Rellenamos los nulos en función del título \n",
        "for titulo in df_titanic['Title'].unique():\n",
        "  filtro_titulo = df_titanic['Title'] == titulo\n",
        "\n",
        "  if len(df_titanic[((filtro_titulo) & (filtro_edad_no_nula))]) > 2:\n",
        "    print(titulo)\n",
        "    df_titanic.loc[((filtro_titulo)&(filtro_edad_nula)), 'Age'] = df_titanic.loc[((filtro_titulo)&(filtro_edad_no_nula)), 'Age'].median()\n",
        "  \n",
        "# Rellenamos los que sigan siendo nulos (títulos solo presentes entre gente sin la edad informada)\n",
        "df_titanic['Age'] = df_titanic['Age'].fillna(df_titanic['Age'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfw614piCcoP"
      },
      "source": [
        "# Visualización de nulos\n",
        "df_titanic[cols].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My1kNOEA69l6"
      },
      "source": [
        "# Eliminamos los nulos de la variable Embarked\n",
        "print(len(df_titanic))\n",
        "df_titanic = df_titanic.dropna(subset=['Embarked'])\n",
        "print(len(df_titanic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkDiqYH9C2GE"
      },
      "source": [
        "## 0304 Dumificación variables categóricas\n",
        "Por último, dumificamos las variables categóricas para convertirlas en numéricas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsTXQzu069pH"
      },
      "source": [
        "# Dumificamos variables categóricas\n",
        "df_titanic_i = pd.get_dummies(df_titanic[cols], \n",
        "                              prefix_sep='_',\n",
        "                              drop_first=True, \n",
        "                              columns=cat_cols)\n",
        "df_titanic_i.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGmAVlJG69sX"
      },
      "source": [
        "df_titanic_i.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FslCSMULDMRG"
      },
      "source": [
        "# 04 Train - Test split\n",
        "Una de las principales medidas contra el sobreajuste consiste en reservar un set de datos para testear el modelo.\n",
        "\n",
        "Utilizaremos una partición del 25%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8FuPLsxDZ91"
      },
      "source": [
        "# Generamos las matrices X e y\n",
        "X = df_titanic_i.drop('Survived',axis=1)\n",
        "y = df_titanic_i['Survived']\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnyFeSi9DaBq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRO6wMepPOJj"
      },
      "source": [
        "# 05 Construcción de árboles de decisión \n",
        "Utilizaremos la librería [scikit learn](https://scikit-learn.org/stable/), la libería básica de referencia para machine learning, para entrenar varios árboles de decisión y comprobar su equilibrio bias-variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXSNgNJrsdva"
      },
      "source": [
        "## 0501 Ejemplo con un modelo\n",
        "Ejemplo de cómo entrenar y evaluar un modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Ox3WCyE4Qi"
      },
      "source": [
        "# Inicializo un árbol con 10 de profundidad\n",
        "modelo = tree.DecisionTreeClassifier(max_depth=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNUQ-MesE4Ux"
      },
      "source": [
        "# Entreno el árbol con el set de entrenamiento\n",
        "modelo = modelo.fit(X=X_train, y=y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_fveGTcE4Yr"
      },
      "source": [
        "# Uso el árbol para predecir sobre el dataset de entrenamiento y de prueba\n",
        "y_pred_train = modelo.predict(X_train)\n",
        "y_pred_test = modelo.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z62sUmfxE_rf"
      },
      "source": [
        "# Cómo de buenas son las predicciones?\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ac_train = round(accuracy_score(y_train, y_pred_train), 4)\n",
        "ac_test = round(accuracy_score(y_test, y_pred_test), 4)\n",
        "\n",
        "print('Precisión en set de entrenamiento :', ac_train)\n",
        "print('Precisión en set de test :', ac_test)\n",
        "print('Degradación: ', round((ac_train-ac_test)/ac_train*100,2), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBIOa6DzFRo1"
      },
      "source": [
        "## 0502 Generamos función\n",
        "Que dado un modelo inicializado, lo entrena y lo evalúa:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZufsD4AMErPV"
      },
      "source": [
        "def entrenar_modelo_y_predecir_classificacion(modelo):\n",
        "  # Entreno el árbol con el set de entrenamiento\n",
        "  modelo = modelo.fit(X=X_train, y=y_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de entrenamiento\n",
        "  y_pred_train = modelo.predict(X_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de test\n",
        "  y_pred_test = modelo.predict(X_test)\n",
        "  # Cómo de buena es la predicción?\n",
        "  ac_train = round(accuracy_score(y_train, y_pred_train), 4)\n",
        "  print('Precisión en set de entrenamiento :', ac_train)\n",
        "  ac_test = round(accuracy_score(y_test, y_pred_test), 4)\n",
        "  print('Precisión en set de test :', ac_test)\n",
        "  print('Degradación: ', round((ac_train-ac_test)/ac_train*100,2), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMPYTpYBErXl"
      },
      "source": [
        "# Inicializo un árbol con 10 de profundidad\n",
        "modelo = tree.DecisionTreeClassifier(max_depth=10)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpc44ulgPFkN"
      },
      "source": [
        "# Inicializo un árbol con 15 de profundidad\n",
        "modelo = tree.DecisionTreeClassifier(max_depth=15)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94EF0Pm_FrC4"
      },
      "source": [
        "## 0503 EJERCICIO: Equilibrio Bias - Variance\n",
        "Tienes varias medidas para controlar el equilibrio bias-variance:\n",
        "\n",
        "\n",
        "*   max_depth determina la profundidad de tu árbol\n",
        "*   min_samples_split tamaño muestral mínimo en un nodo para permitir una partición\n",
        "*   min_samples_leaf = 10 tamaño muestral mínimo en un nodo terminal (en una hoja del árbol)\n",
        "*   min_impurity_decrease mínimo descenso de impuridad que tiene que provocar cada partición\n",
        "\n",
        "Juega con estos valores para encontrar el mejor modelo posible.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWsWxxLQJRLY"
      },
      "source": [
        "modelo = tree.DecisionTreeClassifier(max_depth=15, \n",
        "                                     min_samples_split = 20,\n",
        "                                     min_samples_leaf = 5)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9j7gSmHJhLe"
      },
      "source": [
        "modelo = tree.DecisionTreeClassifier(max_depth=20, \n",
        "                                     min_samples_split = 20,\n",
        "                                     min_samples_leaf = 5, \n",
        "                                     min_impurity_decrease = 0.003)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}