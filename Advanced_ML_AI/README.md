# Clase 1 - Modelos de árboles avanzados 
Profundizamos en modelos de árboles avanzados e introducimos el concepto (en realidad ya conocido) de model ensambles:
- Posible (último) repaso a modelos de árboles de decisión
- Model Ensembles: ¿suma de modelos débiles = modelo fuerte?
  - Bagging: Random Forests
  - Boosting: Gradient Boosting, Stochastic Gradient Boosting, AdaBoost, XGBoost
  - Stacking:
- Creación de pipelines para crear modelos ensamblados
- Modelos de supervivencia

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 1A - Notebook ...: Original | Resuelto
- 1B - Notebook ...: Original | Resuelto 


# Clase 2 - Optimizando modelos: selección de hiperparámetros
Cómo buscar y seleccionar el mejor set de hiperparámetros posible a la hora de entrenar un modelo:
- Principios de búsqueda de hiperparámetros
- Búsqueda de parámetros y selección de features
- Grid search, random search o basados en otras técnicas

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook ...: Original | Resuelto
- 2B - Notebook ...: Original | Resuelto 

# Clase 3 - Introducción a las redes neuronales
Introducción a modelos de redes neuronales:
- Qué es una red neuronal?
- Tipología: Neuronas, Capas, Etc.
Función de activación: sigmoide/relu
- Gradiente Descento y proceso de aprendizaje (backpropagation)
- Función de pérdida
- Sotochastic Gradient Descent
- ver mail con link

Los materiales que utilizaremos son:
- Presentación | Presentación formato claro
- 2A - Notebook ...: Original | Resuelto
- 2B - Notebook ...: Original | Resuelto 
