{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02 C Árboles Decisión sin Overfitting.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNVzKhtpCBnA39JDxRR48mm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_02_Arboles/02_C_%C3%81rboles_Decisi%C3%B3n_sin_Overfitting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R53FGLN8jo1L"
      },
      "source": [
        "# 01 INTRO: Árboles de Decisión\r\n",
        "Explicación de cómo construír árboles de decisión.\r\n",
        "\r\n",
        "Notebook por [Javier Blanco Cordero](https://www.linkedin.com/in/javier-blanco-cordero-71373656/).\r\n",
        "\r\n",
        "### Enlaces de interés\r\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/1iq5k6zECRldUv5so26OsvkExqFJUwKd_CZu18hB-MB8/edit#slide=id.gc2469ceed5_0_0)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSuEDXhPLi8u"
      },
      "source": [
        "## 0101 Qué es un árbol de decisión?\r\n",
        "Un tipo de algoritmo de aprendizaje supervisado que se basa en realizar particiones a partir de distintos niveles de las variables disponibles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHRaho3rsXS"
      },
      "source": [
        "## 0102 Import\r\n",
        "Importamos todas las librerías necesarias para este análisis ([¿No sabes lo que es una librería de Python?](https://www.quora.com/What-is-a-Python-library-and-what-can-I-use-it-for)): pandas, numpy, seaborn, matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be6xiUqjPHI"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import graphviz \r\n",
        "from sklearn import tree\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AblkT14d4Gvt"
      },
      "source": [
        "## 0103 Carga el dataset de coches de segunda mano\r\n",
        "Para probar a hacer árboles de decisión sin overfitting utilizaremos un dataset sobre el precio de distintos coches de segunda mano que he encontrado en Kaggle ([aquí](https://www.kaggle.com/harturo123/online-adds-of-used-cars)). \r\n",
        "\r\n",
        "Podéis encontrar el archivo listo para importar en mi github: 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/coches_usados_esp.csv'. \r\n",
        "\r\n",
        "Importa este dataset en un dataframe llamado **df**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZACcIXOclu"
      },
      "source": [
        "# Url archivo raw\r\n",
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/coches_usados_esp.csv'\r\n",
        "\r\n",
        "# Importa csv\r\n",
        "df = pd.read_csv(url, sep=';')\r\n",
        "\r\n",
        "# Visualización primeras filas\r\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOQJ0AjdYrM"
      },
      "source": [
        "# 02 EDA\r\n",
        "Realizaremos un pequeño análisis exploratorio visual para familiarizarnos con el dataset. \r\n",
        "\r\n",
        "Recuerda que puedes encontrar mis clases sobre análisis exploratorio [aquí](https://github.com/JotaBlanco/TheValley/tree/main/EDA/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGrwhGyaj0-a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1_5T47haV8Q"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LoZpl8rjWEX"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUz-qSwBjaEW"
      },
      "source": [
        "# Visualización coeficientes Pearson\r\n",
        "plt.figure(figsize=(8,7))\r\n",
        "sns.heatmap(np.round(df.corr(),2), \r\n",
        "            vmin=-1, vmax=1, \r\n",
        "            annot=True, cmap=\"coolwarm\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgH2I3otagdU"
      },
      "source": [
        "# 03 EJEMPLO\r\n",
        "Vamos a ver paso a paso cómo realizar un modelo que prediga el precio sin caer en overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCQnyHTcawdU"
      },
      "source": [
        "## 0301 Preparamos los datos\r\n",
        "El dataframe tiene algunos nulos, así como variables categóricas y presencia de ciertas variables que probablemente no queramos usar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAXljoaabIQ5"
      },
      "source": [
        "### 030101 Variables Útiles\r\n",
        "De entre las variables disponibles, veamos cuáles queremos utilizar como predictoras para el estudio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koTejjQJbTmp"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSe15ngNbRsI"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CduKZ0_bntL"
      },
      "source": [
        "cols = ['make', 'model', 'months_old', 'power', 'sale_type', 'num_owners', \r\n",
        "        'gear_type', 'fuel_type', 'kms', 'price']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mByQxiFCbRJY"
      },
      "source": [
        "### 030102 Dumificación de variables categóricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1_P8ceTb_Cy"
      },
      "source": [
        "df_i = pd.get_dummies(df[cols], \r\n",
        "                   prefix_sep='_', \r\n",
        "                   drop_first=True, \r\n",
        "                   columns=['make', 'model', 'sale_type', 'gear_type', 'fuel_type'])\r\n",
        "\r\n",
        "display(len(df_i))\r\n",
        "df_i.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eu6b-OOdCYC"
      },
      "source": [
        "### 030103 Limpieza de nulos\r\n",
        "Con la dumificación hemos eliminado los nulos en las columnas categóricas sin deshacernos de las filas. Queda algún nulo en las variables numéricas?\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTdhLHmVdVDi"
      },
      "source": [
        "df_i.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKE3Tr5tcx1R"
      },
      "source": [
        "df_i[['months_old', 'power', 'num_owners', 'kms', 'price']].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKQcxVgWeFna"
      },
      "source": [
        "# Hay muchos nulos en num_owners\r\n",
        "# Quizás esto tiene que ver con origenes del coche desconocidos?\r\n",
        "# Vamos a limpiar la variable en 1, 2, 3+, nulo y la utilizamos como categórica\r\n",
        "filtro_muchos_owners = df_i['num_owners']>=3\r\n",
        "df_i.loc[filtro_muchos_owners, 'num_owners'] = '3+'\r\n",
        "df_i = pd.get_dummies(df_i, prefix_sep='_', \r\n",
        "                   dummy_na=True,\r\n",
        "                   drop_first=True, \r\n",
        "                   columns=['num_owners'])\r\n",
        "df_i.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wa3pvtGgP9D"
      },
      "source": [
        "df_i[['months_old', 'power', 'kms', 'price']].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6fBmkLdhUH7"
      },
      "source": [
        "for col in ['months_old', 'power', 'kms']:\r\n",
        "  df_i[col] = df_i[col].fillna(df_i[col].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFtfx3TXhfKR"
      },
      "source": [
        "df_i.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NQpz3yMhlP8"
      },
      "source": [
        "##0302 Train - test split\r\n",
        "Separamos el set de datos en dos utilizando [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RY1xSE0ibVy"
      },
      "source": [
        "X = df_i.drop('price',axis=1)\r\n",
        "y = df_i['price']\r\n",
        "\r\n",
        "len(X), len(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABXKI_CniEME"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGzX2Ku3jQv5"
      },
      "source": [
        "## 0303 Entrenamos el árbol de decisión\r\n",
        "Sobre el set de entrenamiento, comprobamos el modelo sobre el set de test.\r\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y12bT7TSj9gq"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=10)\r\n",
        "# Entreno el árbol con el set de entrenamiento\r\n",
        "modelo = modelo.fit(X=X_train, y=y_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de entrenamiento\r\n",
        "y_pred_train = modelo.predict(X_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de test\r\n",
        "y_pred_test = modelo.predict(X_test)\r\n",
        "# Cómo de buena es la predicción?\r\n",
        "print('RMSE en set de entrenamiento :', mean_squared_error(y_train, y_pred_train, squared=False))\r\n",
        "print('RMSE en set de test :', mean_squared_error(y_test, y_pred_test, squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-eKMEkpltgt"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=5)\r\n",
        "# Entreno el árbol con el set de entrenamiento\r\n",
        "modelo = modelo.fit(X=X_train, y=y_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de entrenamiento\r\n",
        "y_pred_train = modelo.predict(X_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de test\r\n",
        "y_pred_test = modelo.predict(X_test)\r\n",
        "# Cómo de buena es la predicción?\r\n",
        "print('RMSE en set de entrenamiento :', mean_squared_error(y_train, y_pred_train, squared=False))\r\n",
        "print('RMSE en set de test :', mean_squared_error(y_test, y_pred_test, squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt-I-N3Glwwp"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=50)\r\n",
        "# Entreno el árbol con el set de entrenamiento\r\n",
        "modelo = modelo.fit(X=X_train, y=y_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de entrenamiento\r\n",
        "y_pred_train = modelo.predict(X_train)\r\n",
        "# Uso el árbol para predecir sobre el dataset de test\r\n",
        "y_pred_test = modelo.predict(X_test)\r\n",
        "# Cómo de buena es la predicción?\r\n",
        "print('RMSE en set de entrenamiento :', mean_squared_error(y_train, y_pred_train, squared=False))\r\n",
        "print('RMSE en set de test :', mean_squared_error(y_test, y_pred_test, squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orWBwiPxm5Oi"
      },
      "source": [
        "def entrenar_modelo_y_predecir(modelo):\r\n",
        "  # Entreno el árbol con el set de entrenamiento\r\n",
        "  modelo = modelo.fit(X=X_train, y=y_train)\r\n",
        "  # Uso el árbol para predecir sobre el dataset de entrenamiento\r\n",
        "  y_pred_train = modelo.predict(X_train)\r\n",
        "  # Uso el árbol para predecir sobre el dataset de test\r\n",
        "  y_pred_test = modelo.predict(X_test)\r\n",
        "  # Cómo de buena es la predicción?\r\n",
        "  print('RMSE en set de entrenamiento :', mean_squared_error(y_train, y_pred_train, squared=False))\r\n",
        "  print('RMSE en set de test :', mean_squared_error(y_test, y_pred_test, squared=False))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY1urTMJnI7S"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=25)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psH9u3Gkl4hr"
      },
      "source": [
        "## 0304 Probamos medidas contra el overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOKrcoHimAjh"
      },
      "source": [
        "### 030401 min_samples_split\r\n",
        "Tamaño muestral mínimo para permitir una partición."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbyvemCimZ7Z"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=10, min_samples_split=20)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHtM6hxVmpvS"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=15, min_samples_split=20)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PM_oDEfWmuzL"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=15, min_samples_split=25)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WHNSaNfmzDL"
      },
      "source": [
        "### 030402 min_samples_leaf\r\n",
        "Tamaño muestral mínimo en una hoja."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzpo8en2nx8j"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=15, \r\n",
        "                                    min_samples_split=25,\r\n",
        "                                    min_samples_leaf = 10)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvKhW2ANoG_T"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=20, \r\n",
        "                                    min_samples_split=20,\r\n",
        "                                    min_samples_leaf = 2)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffxLpFnZo0zF"
      },
      "source": [
        "### 030402 min_samples_leaf\r\n",
        "Mínimo descenso de impuridad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FADakO2_pHsi"
      },
      "source": [
        "# Inicializo un árbol\r\n",
        "modelo = tree.DecisionTreeRegressor(max_depth=15, \r\n",
        "                                    min_samples_split=25,\r\n",
        "                                    min_impurity_decrease = 0.25)\r\n",
        "# Entrenamos y predecimos con dicho modelo\r\n",
        "entrenar_modelo_y_predecir(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V66-xgckYMQs"
      },
      "source": [
        "# 06 EJERCICIO TITANIC\r\n",
        "Recordais el dataset del Titanic?\r\n",
        "\r\n",
        "Vamos a resolver este problema teniendo en cuenta todo lo que sabemos ya. El objetivo es crear una árbol de decisión que prediga si un pasajero falleció o no (pasajeros cuyos datos no conocemos todavía).\r\n",
        "\r\n",
        "Toma las medidas oportunas para que tu modelo sea lo más preciso posible sin caer en overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDiMGl7xOm6o"
      },
      "source": [
        "## 0601 Importa el dataset\r\n",
        "Puedes encontrarlo en mi github. Este es el link al archivo raw: https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv.\r\n",
        "\r\n",
        "Importa los datos en un dataframe llamado dataframe **df_titanic**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYiZbvGgYGzt"
      },
      "source": [
        "# Url archivo raw\r\n",
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv'\r\n",
        "\r\n",
        "# Importa csv\r\n",
        "df_titanic = pd.read_csv(url)\r\n",
        "\r\n",
        "# Visualización primeras filas\r\n",
        "df_titanic.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60P6G1BxzWBD"
      },
      "source": [
        "df_titanic.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS0_ouF8qiVz"
      },
      "source": [
        "## 0602 Prepara los datos\r\n",
        "Quédate con las variables interesantes, dumifica las categóricas y limpia los nulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58IzhBMiqgNK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvI6ugAjqyAT"
      },
      "source": [
        "## 0603 Train - test split\r\n",
        "Utiliza una partición del 30% para tu set de pruebas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1-gJw0gq9sY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgZiyRv7q_09"
      },
      "source": [
        "## 0404 Entrena varios árboles\r\n",
        "Entrena varios árboles de decisión controlando los distintos parámetros para buscar el punto óptimo entre bias y varianza."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rW5nSkdUrJzA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}