{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03C | Introducción Random Forests.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMCiStsBOjBo4g8NXdf9ru2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03C_%7C_Introducci%C3%B3n_Random_Forests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R53FGLN8jo1L"
      },
      "source": [
        "# 01 INTRO: Random Forest\n",
        "Introducción a modelos de bagging de árboles de decisión (Random Forests).\n",
        "\n",
        "Notebook por [Javier Blanco Cordero](https://www.linkedin.com/in/javier-blanco-cordero-71373656/).\n",
        "\n",
        "### Enlaces de interés\n",
        "*   [Slides de presentación](https://docs.google.com/presentation/d/1jRg7Dk2y_2_fxnC_Jpj5aWcqgW9t1KAd7izdmWzv9Sk/edit?usp=sharing)\n",
        "*   [Enlace a este notebook](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03C_%7C_Introducci%C3%B3n_Random_Forests.ipynb)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSuEDXhPLi8u"
      },
      "source": [
        "## 0101 Qué es un Random Forest?\n",
        "Es una agregación de árboles de decisión de tipo bagging (**B**ootstrapping + Aggregation)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnHRaho3rsXS"
      },
      "source": [
        "## 0102 Import\n",
        "Importamos todas las librerías necesarias para este análisis ([¿No sabes lo que es una librería de Python?](https://www.quora.com/What-is-a-Python-library-and-what-can-I-use-it-for)): pandas, numpy, seaborn, matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4be6xiUqjPHI"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import graphviz\n",
        "from sklearn import tree\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AblkT14d4Gvt"
      },
      "source": [
        "## 0103 Carga el dataset del Titanic\n",
        "Volvamos con el Dataset del Titanic\n",
        "\n",
        "Vamos a comparar el rendimiento de un Random Forest con los modelos de árboles de decisión que creamos en el [notebook 3B](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03B_%7C_Repaso_II_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb).\n",
        "\n",
        "Este es el link al archivo raw: https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv.\n",
        "\n",
        "Importa los datos en un dataframe llamado **dataframe df_titanic**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMZACcIXOclu"
      },
      "source": [
        "# Url archivo raw\n",
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/titanic.csv'\n",
        "\n",
        "# Importa csv\n",
        "df_titanic = pd.read_csv(url)\n",
        "\n",
        "# Visualización primeras filas\n",
        "df_titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jj4KI0FDBC-K"
      },
      "source": [
        "## 0104 Limpieza del Dataset\n",
        "Limpiamos los nulos y creamos la variable Title como en el [Notebook 3B](https://colab.research.google.com/github/JotaBlanco/TheValley/blob/main/Arboles/Clase_03_Arboles/03B_%7C_Repaso_II_sobre_%C3%81rboles_Decisi%C3%B3n.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBiiIka2A_P-"
      },
      "source": [
        "# Creamos una nueva variable Título (es opcional, pero podría ayudar al modelo)\n",
        "df_titanic['Title'] = [name.split(\",\")[1].split(\".\")[0][1:] for name in df_titanic['Name']]\n",
        "df_titanic.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huJ7oPGYBel7"
      },
      "source": [
        "# Columnas con las que nos quedamos\n",
        "cols = ['Survived', \n",
        "        'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title']\n",
        "\n",
        "# De ellas, cuáles son categóricas\n",
        "cat_cols = ['Sex', 'Embarked', 'Title']\n",
        "\n",
        "# Visualizamos las columnas con las que nos hemos quedado\n",
        "df_titanic[cols].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn7Z8sdPBepk"
      },
      "source": [
        "# Rellenamos los nulos de las variables numéricas (edad)\n",
        "df_titanic[cols].isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVMI9BAQBlLo"
      },
      "source": [
        "# Rellenamos los nulos de la variable edad de una forma avanzada:\n",
        "# calculando la media para cada título\n",
        "\n",
        "filtro_edad_nula = df_titanic['Age'].isna()\n",
        "filtro_edad_no_nula = df_titanic['Age'].notnull()\n",
        "\n",
        "# Rellenamos los nulos en función del título \n",
        "for titulo in df_titanic['Title'].unique():\n",
        "  filtro_titulo = df_titanic['Title'] == titulo\n",
        "\n",
        "  if len(df_titanic[((filtro_titulo) & (filtro_edad_no_nula))]) > 2:\n",
        "    print(titulo)\n",
        "    df_titanic.loc[((filtro_titulo)&(filtro_edad_nula)), 'Age'] = df_titanic.loc[((filtro_titulo)&(filtro_edad_no_nula)), 'Age'].median()\n",
        "  \n",
        "# Rellenamos los que sigan siendo nulos (títulos solo presentes entre gente sin la edad informada)\n",
        "df_titanic['Age'] = df_titanic['Age'].fillna(df_titanic['Age'].median())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLI5X9CyBobX"
      },
      "source": [
        "# Eliminamos los nulos de la variable Embarked\n",
        "print(len(df_titanic))\n",
        "df_titanic = df_titanic.dropna(subset=['Embarked'])\n",
        "print(len(df_titanic))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21-yN-efBoe2"
      },
      "source": [
        "# Dumificamos variables categóricas\n",
        "df_titanic_i = pd.get_dummies(df_titanic[cols], \n",
        "                              prefix_sep='_',\n",
        "                              drop_first=True, \n",
        "                              columns=cat_cols)\n",
        "df_titanic_i.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWB003sfBuvs"
      },
      "source": [
        "## 0105 Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8_lZjJNBoh3"
      },
      "source": [
        "# Generamos las matrices X e y\n",
        "X_titanic = df_titanic_i.drop('Survived',axis=1)\n",
        "y_titanic = df_titanic_i['Survived']\n",
        "\n",
        "X_titanic.shape, y_titanic.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA1EnqzxB0ew"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_titanic, \n",
        "                                                    y_titanic, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBOQJ0AjdYrM"
      },
      "source": [
        "# 02 Entrenamiento árbol de decisión\n",
        "Entrenamos un árbol de decisión tomando medidas para evitar el overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ-FEpCkCAR8"
      },
      "source": [
        "def entrenar_modelo_y_predecir_classificacion(modelo):\n",
        "  # Entreno el árbol con el set de entrenamiento\n",
        "  modelo = modelo.fit(X=X_train, y=y_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de entrenamiento\n",
        "  y_pred_train = modelo.predict(X_train)\n",
        "  # Uso el árbol para predecir sobre el dataset de test\n",
        "  y_pred_test = modelo.predict(X_test)\n",
        "  # Cómo de buena es la predicción?\n",
        "  ac_train = round(accuracy_score(y_train, y_pred_train), 4)\n",
        "  print('Precisión en set de entrenamiento :', ac_train)\n",
        "  ac_test = round(accuracy_score(y_test, y_pred_test), 4)\n",
        "  print('Precisión en set de test :', ac_test)\n",
        "  print('Degradación: ', round((ac_train-ac_test)/ac_train*100,2), '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAxIPaSACAVh"
      },
      "source": [
        "modelo = tree.DecisionTreeClassifier(max_depth=20, \n",
        "                                     min_samples_split = 20,\n",
        "                                     min_samples_leaf = 5, \n",
        "                                     min_impurity_decrease = 0.003)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1MXDCO6cD0O"
      },
      "source": [
        "# con export_graphviz\n",
        "dot_data = tree.export_graphviz(modelo, \n",
        "                                out_file=None, \n",
        "                                feature_names=list(X_titanic.columns)) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OJS0b4R5ZNh"
      },
      "source": [
        "# 03 Entrenamiento Random Forest\n",
        "Ahora comparamos el rendimiento del árbol de decisión con un Random Forest.\n",
        "http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvgN8D2VCoRk"
      },
      "source": [
        "# Importamos el modelo desde Sklearn\n",
        "from sklearn import ensemble"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ervsyl8CzCf"
      },
      "source": [
        "modelo = ensemble.RandomForestClassifier(n_estimators = 200,\n",
        "                                         max_depth = 3, \n",
        "                                         min_samples_split = 10,\n",
        "                                         min_samples_leaf = 5)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecE8BUW-CzF2"
      },
      "source": [
        "modelo = ensemble.RandomForestClassifier(n_estimators = 250,\n",
        "                                         max_features = \"auto\",\n",
        "                                         max_depth = 5, \n",
        "                                         min_samples_split = 5,\n",
        "                                         min_samples_leaf = 3)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHOAZOsfZH87"
      },
      "source": [
        "# 04 EJERCICIO\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnQFvk5wgKGA"
      },
      "source": [
        "## 0401 Importa Dataset Diabetes\n",
        "Vamos a utilizar el dataset del notebook 3A (Diabetes).\n",
        "\n",
        "Impórtalo utilizando el archivo raw: 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/diabetesIndia.csv'.\n",
        "\n",
        "Guárdalo en el **dataframe df**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVKFwAXnCzJH"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/JotaBlanco/TheValley/main/Data/diabetesIndia.csv'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHqVm6uYgeXc"
      },
      "source": [
        "## 0402 Limpia el dataset\n",
        "Comprueba el dataset (hay nulos) y prepáralo si es necesario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv-J8JvifBxH"
      },
      "source": [
        "# Rellenamos los nulos de las variables numéricas (edad)\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyY_O5ihhxp4"
      },
      "source": [
        "## 0403 Train-Test split\n",
        "Genera el set de pruebas (test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzRaemIKfIhu"
      },
      "source": [
        "# Generamos las matrices X e y\n",
        "X = df.drop('Outcome',axis=1)\n",
        "y = df['Outcome']\n",
        "\n",
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJx193nOfSRs"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42)\n",
        "\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-PFKRkjh4iX"
      },
      "source": [
        "## 0404 Árbol de Decisión\n",
        "Encuentra el mejor árbol de decisión posible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTkHe6X0fUfF"
      },
      "source": [
        "modelo = tree.DecisionTreeClassifier(max_depth=15, \n",
        "                                     min_samples_split = 20,\n",
        "                                     min_samples_leaf = 10, \n",
        "                                     min_impurity_decrease = 0.005)\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2CzEX7TiH0b"
      },
      "source": [
        "## 0405 Random Forest\n",
        "Encuentra el mejor modelo de rándom forest posible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_c2wOvifYTt"
      },
      "source": [
        "modelo = ensemble.RandomForestClassifier(n_estimators = 500,\n",
        "                                         max_features = \"auto\",\n",
        "                                         max_depth = 3, \n",
        "                                         min_samples_split = 20,\n",
        "                                         min_samples_leaf = 5, \n",
        "                                         min_impurity_decrease = 0.005)\n",
        "\n",
        "# Entrenamos y predecimos con dicho modelo\n",
        "entrenar_modelo_y_predecir_classificacion(modelo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OKhXrNL7-D7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}